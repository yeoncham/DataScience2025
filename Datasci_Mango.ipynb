{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c18115b-33e1-495e-9e65-d91003d448eb",
   "metadata": {},
   "source": [
    "# 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c16c15cc-abb9-402b-8a08-155b649b4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.tree import plot_tree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "x = data.drop(['ID', 'Cancer'], axis=1)\n",
    "y = data['Cancer']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.45, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed9916-b03c-4faa-a4ba-7ffb2b5dde77",
   "metadata": {},
   "source": [
    "# 2. 전처리기 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89d4684-d345-431f-8641-46c3f66555c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_new_feature(BaseEstimator, TransformerMixin):\n",
    "    def t4_category(self, x):\n",
    "        if x < 6:\n",
    "            return 'T4_Low'\n",
    "        elif x > 11.98:\n",
    "            return 'T4_High'\n",
    "        else:\n",
    "            return 'T4_Normal'\n",
    "    def t3_category(self, x):\n",
    "        if x < 1.4:\n",
    "            return 'T3_Low'\n",
    "        elif x > 3:\n",
    "            return 'T3_High'\n",
    "        else:\n",
    "            return 'T3_Normal'\n",
    "    def tsh_category(self, x):\n",
    "        if x < 0.27:\n",
    "            return 'TSH_Low'\n",
    "        elif x > 4.2:\n",
    "            return 'TSH_High'\n",
    "        else:\n",
    "            return 'TSH_Normal'\n",
    "    \n",
    "    def age_category(self, x):\n",
    "        if x < 30:\n",
    "            return 'Young'\n",
    "        elif x < 50:\n",
    "            return 'Middle'\n",
    "        elif x < 65:\n",
    "            return 'Senior'\n",
    "        else:\n",
    "            return 'Elderly'\n",
    "    \n",
    "    def nodule_size_category(self, x):\n",
    "        if x < 1.0:\n",
    "            return 'Small'\n",
    "        elif x < 2.0:\n",
    "            return 'Medium'\n",
    "        elif x < 4.0:\n",
    "            return 'Large'\n",
    "        else:\n",
    "            return 'VeryLarge'\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x, y=None):\n",
    "        x = x.copy()\n",
    "        \n",
    "        x['T3_Result_Cat'] = pd.cut(x['T3_Result'], \n",
    "                                   bins=[-np.inf, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, np.inf],\n",
    "                                   labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "        \n",
    "        x['T3_Cat'] = x['T3_Result'].apply(lambda x : self.t3_category(x))\n",
    "        x['T4_Cat'] = x['T4_Result'].apply(lambda x : self.t4_category(x))\n",
    "        \n",
    "        x['Race&T3'] = x['Race'].astype(str) + x['T3_Result_Cat'].astype(str)\n",
    "        x['Family&Iodine'] = x['Family_Background'].astype(str) + x['Iodine_Deficiency'].astype(str)\n",
    "        x['T3&T4'] = x['T3_Cat'].astype(str) + x['T4_Cat'].astype(str)\n",
    "        return x\n",
    "\n",
    "class dropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, x, y=None):\n",
    "        x = x.copy()\n",
    "        return x.drop(self.columns, axis=1)\n",
    "\n",
    "class custom_encoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoder = None\n",
    "        self.num_feature = None\n",
    "        self.cat_feature = None\n",
    "        self.OneHot_feature = None\n",
    "    def fit(self, x, y=None):\n",
    "        self.num_feature = x.select_dtypes('number').columns.to_list()\n",
    "        self.cat_feature = x.select_dtypes(['object', 'category']).columns.to_list()\n",
    "        self.encoder = ColumnTransformer([\n",
    "            ('OneHot', OneHotEncoder(sparse_output=False), self.cat_feature),\n",
    "            ('Scaler', StandardScaler(), self.num_feature)\n",
    "        ])\n",
    "        self.encoder.fit(x)\n",
    "        self.OneHot_feature = self.encoder.named_transformers_['OneHot'].get_feature_names_out(self.cat_feature).tolist()\n",
    "        \n",
    "        return self\n",
    "    def transform(self, x, y=None):\n",
    "        x = x.copy()\n",
    "        encoded = self.encoder.transform(x)\n",
    "        \n",
    "        return pd.DataFrame(\n",
    "            encoded,\n",
    "            columns=self.OneHot_feature + self.num_feature\n",
    "        )\n",
    "\n",
    "# 파이프라인 구성 \n",
    "useless_feature = ['T3_Result', 'T4_Result', 'TSH_Result', \n",
    "                   'Age', 'Nodule_Size', \n",
    "                   'T3_Cat', 'T4_Cat', 'T3_Result_Cat']\n",
    "preprocessor = Pipeline([\n",
    "    ('add_new_feature', add_new_feature()),\n",
    "    ('dropper', dropper(useless_feature)),\n",
    "    ('encoder', custom_encoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1524f86-64f3-4585-b9f6-eced33d6f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumy_pre = Pipeline([\n",
    "    ('add_feature', add_new_feature()),\n",
    "    ('dropper', dropper(useless_feature+['Race&T3', 'Family&Iodine', 'T3&T4'])), \n",
    "    ('encoder', custom_encoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d4da42-75dc-41b8-bae3-d4b554532d0d",
   "metadata": {},
   "source": [
    "# 3. 모델 학습 및 교차검증 (10-fold)\n",
    "\n",
    "1. StratifiedKFold를 이용해 클래스 비율을 일정하게 유지하면서 교차검증을 시행\n",
    "2. 각 fold를 검증 셋으로 사용하여 파생 특성 추가 전 / 후의 성능을 기록\n",
    "3. 파생 특성 추가 전 / 후의 성능에 대해 대응표본 t-검정을 시행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bd108eb-1bcb-4482-aaa4-1ab229a0ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       특성 추가 후          특성 추가 전\n",
      "=============================================================\n",
      "Fold | Acc(pre)            | Acc(dumy)\n",
      "-------------------------------------------------------------\n",
      "   1 |  0.8592             |   0.8369\n",
      "   2 |  0.8546             |   0.8340\n",
      "   3 |  0.8498             |   0.8329\n",
      "   4 |  0.8636             |   0.8494\n",
      "   5 |  0.8540             |   0.8290\n",
      "   6 |  0.8586             |   0.8394\n",
      "   7 |  0.8561             |   0.8315\n",
      "   8 |  0.8606             |   0.8429\n",
      "   9 |  0.8623             |   0.8393\n",
      "  10 |  0.8544             |   0.8448\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "accs_preprocessor = []\n",
    "accs_dumy_pre = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"       특성 추가 후          특성 추가 전\")\n",
    "print(\"=============================================================\")\n",
    "print(\"Fold | Acc(pre)            | Acc(dumy)\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(x_train, y_train), start=1):\n",
    "    x_tr, x_val = x_train.iloc[train_idx], x_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    # ====== preprocessor ======\n",
    "    x_tr_pre = preprocessor.fit_transform(x_tr)\n",
    "    x_val_pre = preprocessor.transform(x_val)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    x_smote, y_smote = smote.fit_resample(x_tr_pre, y_tr)\n",
    "\n",
    "    model1 = RandomForestClassifier(random_state=42)\n",
    "    model1.fit(x_smote, y_smote)\n",
    "    y_pred_pre = model1.predict(x_val_pre)\n",
    "\n",
    "    acc_pre = accuracy_score(y_val, y_pred_pre)\n",
    "    accs_preprocessor.append(acc_pre)\n",
    "   \n",
    "    # ====== dumy_pre ======\n",
    "    x_tr_dumy = dumy_pre.fit_transform(x_tr)\n",
    "    x_val_dumy = dumy_pre.transform(x_val)\n",
    "    smote_dumy = SMOTE(random_state=42)\n",
    "    x_smote_dumy, y_smote_dumy = smote_dumy.fit_resample(x_tr_dumy, y_tr)\n",
    "\n",
    "    model2 = RandomForestClassifier(random_state=42)\n",
    "    model2.fit(x_smote_dumy, y_smote_dumy)\n",
    "    y_pred_dumy = model2.predict(x_val_dumy)\n",
    "\n",
    "    acc_dumy = accuracy_score(y_val, y_pred_dumy)\n",
    "    accs_dumy_pre.append(acc_dumy)\n",
    "    \n",
    "    # 각 fold 결과 출력\n",
    "    print(f\"{fold:>4} |  {acc_pre:.4f}             |   {acc_dumy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73821f98-be2f-4f4b-b6d2-579bd8f2f473",
   "metadata": {},
   "source": [
    "# 4. 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f89e5fc-d551-4cae-bbc3-d10b8012dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 전체 평균 성능 비교 ===\n",
      "파생 특성 추가 전\n",
      "정확도 : 0.838 ±0.006\n",
      "\n",
      "파생 특성 추가 후\n",
      "정확도 : 0.857 ±0.004\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 전체 평균 성능 비교 ===\")\n",
    "print(\"파생 특성 추가 전\")\n",
    "print(f\"정확도 : {np.mean(accs_dumy_pre).round(3)} ±{np.std(accs_dumy_pre).round(3)}\")\n",
    "\n",
    "print()\n",
    "print(\"파생 특성 추가 후\")\n",
    "print(f\"정확도 : {np.mean(accs_preprocessor).round(3)} ±{np.std(accs_preprocessor).round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a243763f-cee3-48b3-abef-2eedb5646127",
   "metadata": {},
   "source": [
    "# 5 대응 표본 t-검정 시행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911f466-b775-49dc-a4ef-ce5a2f7da0e7",
   "metadata": {},
   "source": [
    "귀무가설 : ___파생변수 추가 전후의 성능 변화가 없을 것이다___   \n",
    "대립가설 : ___파생변수 추가 전후의 유의미한 성능 증가가 있을 것이다___   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fe48f68-a106-44c3-b312-197668011120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 단측 대응 표본 t-검정 결과 =====\n",
      "[Accuracy]  t-stat: 12.5299 | p-value: 0.0000\n",
      "Accuracy는 preprocessor가 유의미하게 더 높습니다.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "import numpy as np\n",
    "\n",
    "# numpy 배열로 변환\n",
    "acc_pre = np.array(accs_preprocessor)\n",
    "acc_dumy = np.array(accs_dumy_pre)\n",
    "\n",
    "# === Accuracy 단측 t-test ===\n",
    "t_stat_acc, p_val_acc_two_sided = ttest_rel(acc_pre, acc_dumy)\n",
    "p_val_acc_one_sided = p_val_acc_two_sided / 2\n",
    "print(\"===== 단측 대응 표본 t-검정 결과 =====\")\n",
    "print(f\"[Accuracy]  t-stat: {t_stat_acc:.4f} | p-value: {p_val_acc_one_sided:.4f}\")\n",
    "if p_val_acc_one_sided < 0.05 and t_stat_acc > 0:\n",
    "    print(\"Accuracy는 preprocessor가 유의미하게 더 높습니다.\")\n",
    "else:\n",
    "    print(\"Accuracy 차이는 유의하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5af659-b968-4ed4-afde-1b9f5f438a4a",
   "metadata": {},
   "source": [
    "# 6. 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e69e0c-7a7b-4c4e-b490-1ea70a0503b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "\n",
      "Best parameters: {'class_weight': 'balanced', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV를 통한 하이퍼파라미터 튜닝\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200], # 랜덤 포레스트의 사용할 트리의 개수\n",
    "    'max_depth': [10, None], # 개별 트리의 최대 깊이\n",
    "    'min_samples_split': [2, 5, 10], # 노드를 분할하기 위한 최소 샘플 수\n",
    "    'min_samples_leaf': [1, 2, 4], # 리프 노드가 되기 위한 최소 샘플 \n",
    "    'max_features': ['sqrt', 'log2'], # 각 노드를 분할할 때 고려할 특성의 개수\n",
    "    'class_weight': ['balanced', None] # balanced: 클래스에 반비례하는 가중치 자동 부여 / None: 가중치 없음\n",
    "}\n",
    "# 파생변수 추가 된 전처리기로 전처리\n",
    "x_train_processed = preprocessor.fit_transform(x_train)\n",
    "x_test_processed = preprocessor.transform(x_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train_processed, y_train)\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross validation\n",
    "    scoring=\"roc_auc\",  # roc_auc로 평가\n",
    "    n_jobs=-1,  # 모든 CPU 코어 사용\n",
    "    verbose=1 # 각 조합에 대한 진행 상황 출력\n",
    ")\n",
    "\n",
    "rf_grid.fit(x_train_smote, y_train_smote)\n",
    "\n",
    "# 최적 파라미터 출력\n",
    "print()\n",
    "print(f\"Best parameters: {rf_grid.best_params_}\")\n",
    "best_model = rf_grid.best_estimator_\n",
    "y_pred_optimized = best_model.predict(x_test_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9fc547-7ee6-4cee-bc44-7b7e3260bb75",
   "metadata": {},
   "source": [
    "# 7. 모델의 튜닝 전후 정확도 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e1351fd-67aa-4a96-a24d-ed3fcc679b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 accuracy |  0.8646\n",
      "fold 2 accuracy |  0.8588\n",
      "fold 3 accuracy |  0.8550\n",
      "fold 4 accuracy |  0.8694\n",
      "fold 5 accuracy |  0.8627\n",
      "fold 6 accuracy |  0.8648\n",
      "fold 7 accuracy |  0.8598\n",
      "fold 8 accuracy |  0.8675\n",
      "fold 9 accuracy |  0.8667\n",
      "fold 10 accuracy |  0.8585\n"
     ]
    }
   ],
   "source": [
    "# 튜닝한 모델에 대한 교차 검증\n",
    "accs_best_model = []\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(x_train, y_train), start=1):\n",
    "    x_tr, x_val = x_train.iloc[train_idx], x_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    x_tr_proc = preprocessor.fit_transform(x_tr)\n",
    "    x_val_proc = preprocessor.transform(x_val)\n",
    "    x_tr_proc, y_tr = SMOTE(random_state=42).fit_resample(x_tr_proc, y_tr)\n",
    "\n",
    "    model_best = RandomForestClassifier(**rf_grid.best_params_, random_state=42)\n",
    "    model_best.fit(x_tr_proc, y_tr)\n",
    "\n",
    "    y_val_pred = model_best.predict(x_val_proc)\n",
    "    acc_best = accuracy_score(y_val, y_val_pred)\n",
    "    accs_best_model.append(acc_best)\n",
    "    print(f\"fold {fold} accuracy |  {acc_best:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8174e5f-c258-45ab-a465-b2075eeefbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.863 ±0.004\n"
     ]
    }
   ],
   "source": [
    "print(f\"정확도 : {np.mean(accs_best_model).round(3)} ±{np.std(accs_best_model).round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc38b67c-3215-46d1-86f0-fcc9d031860c",
   "metadata": {},
   "source": [
    "## 튜닝 전과 튜닝 후의 t-검정\n",
    "귀무가설 : ___튜닝 전과 튜닝 후의 평균 차이는 없다___   \n",
    "대립가설 : ___튜닝 후 모델이 정확도 평균이 높다___   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09619bfc-b064-4ccf-82dd-c27047158bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 튜닝 전후 정확도에 대한 t-검정 =====\n",
      "t-stat: 11.3173, p-value: 1.266128374775973e-06\n",
      "튜닝된 모델이 유의미하게 더 정확도가 높습니다.\n"
     ]
    }
   ],
   "source": [
    "# 튜닝 전과 튜닝 후 사이의 통계 검정\n",
    "t_stat, p_val = ttest_rel(accs_best_model, accs_preprocessor) # 튜닝 후: accs_best_model / 튜닝 전: accs_preprocessor\n",
    "\n",
    "print(\"\\n===== 튜닝 전후 정확도에 대한 t-검정 =====\")\n",
    "print(f\"t-stat: {t_stat:.4f}, p-value: {p_val}\")\n",
    "if p_val < 0.05 and t_stat > 0:\n",
    "    print(\"튜닝된 모델이 유의미하게 더 정확도가 높습니다.\")\n",
    "else:\n",
    "    print(\"튜닝 후 정확도 향상은 통계적으로 유의하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbacf8-a16f-4984-8335-c8a8d40d960f",
   "metadata": {},
   "source": [
    "# 8. 베이스 모델과 최적화된 모델의 성능 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd255dee-4fb0-4927-a022-3da89e64fc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 최종 테스트셋 성능 비교 =========\n",
      "파생변수 없는 모델 (base model)     정확도 : 0.8364\n",
      "파생변수 + 튜닝된 모델 (best model) 정확도 : 0.8596\n",
      "정확도 차이 (best - base) : 0.0233\n"
     ]
    }
   ],
   "source": [
    "# 베이스 모델 최종 학습 - (파생변수 추가가 없는 모델)\n",
    "x_train_dumy = dumy_pre.fit_transform(x_train)\n",
    "x_test_dumy = dumy_pre.transform(x_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_dumy_smote, y_train_dumy_smote = smote.fit_resample(x_train_dumy, y_train)\n",
    "model2_final = RandomForestClassifier(random_state=42)\n",
    "model2_final.fit(x_train_dumy_smote, y_train_dumy_smote)\n",
    "y_pred_dumy_final = model2_final.predict(x_test_dumy)\n",
    "acc_dumy_final = accuracy_score(y_test, y_pred_dumy_final)\n",
    "\n",
    "# 튜닝 후 모델 최종 학습\n",
    "x_train_processed = preprocessor.fit_transform(x_train)\n",
    "x_test_processed = preprocessor.transform(x_test)\n",
    "x_train_smote, y_train_smote = SMOTE(random_state=42).fit_resample(x_train_processed, y_train)\n",
    "best_model_final = RandomForestClassifier(**rf_grid.best_params_, random_state=42)\n",
    "best_model_final.fit(x_train_smote, y_train_smote)\n",
    "\n",
    "# 예측 및 정확도 계산\n",
    "y_pred_best_final = best_model_final.predict(x_test_processed)\n",
    "acc_best_final = accuracy_score(y_test, y_pred_best_final)\n",
    "\n",
    "\n",
    "# 비교 출력\n",
    "# --------------------------------------------------\n",
    "print(\"========= 최종 테스트셋 성능 비교 =========\")\n",
    "print(f\"파생변수 없는 모델 (base model)     정확도 : {acc_dumy_final:.4f}\")\n",
    "print(f\"파생변수 + 튜닝된 모델 (best model) 정확도 : {acc_best_final:.4f}\")\n",
    "print(f\"정확도 차이 (best - base) : {(acc_best_final - acc_dumy_final):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16695ed-7f84-434e-9d45-61472f6faa97",
   "metadata": {},
   "source": [
    "# 9. 파생변수들에 대한 가설 검정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e8eaee5-fa36-4790-b778-90aaa184aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "def t4_category(x):\n",
    "    if x < 6:\n",
    "        return 'T4_Low'\n",
    "    elif x > 11.98:\n",
    "        return 'T4_High'\n",
    "    else:\n",
    "        return 'T4_Normal'\n",
    "def t3_category(x):\n",
    "    if x < 1.4:\n",
    "        return 'T3_Low'\n",
    "    elif x > 3:\n",
    "        return 'T3_High'\n",
    "    else:\n",
    "        return 'T3_Normal'\n",
    "data = pd.read_csv(\"train.csv\") # 전체 데이터셋에 대하여 카이제곱 검정\n",
    "data[\"T3_Cat\"] = data[\"T3_Result\"].apply(t3_category)\n",
    "data[\"T4_Cat\"] = data[\"T4_Result\"].apply(t4_category)\n",
    "data[\"T3&T4\"] = data[\"T3_Cat\"] + \"_\" + data[\"T4_Cat\"]\n",
    "data['Race_T3'] = data['Race'].astype(str) + data['T3_Cat'].astype(str)\n",
    "data['Race_T3'] = data['Race_T3'].astype('object')\n",
    "data['Family&Iodine'] = data['Family_Background'].astype(str) + \"_\" + data['Iodine_Deficiency'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25585217-7728-4bd8-b167-2d08590be827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3호르몬 수치 -> 갑상선 암 발병\n",
      "카이제곱 통계량: 1.3974\n",
      "p-value:  0.4972\n",
      "\n",
      "T4호르몬 수치 -> 갑상선 암 발병\n",
      "카이제곱 통계량: 1.6389\n",
      "p-value:  0.4407\n",
      "\n",
      "T3호르몬&T4호르몬 -> 갑상선 암 발병\n",
      "카이제곱 통계량: 19.1033\n",
      "p-value:  0.0143\n"
     ]
    }
   ],
   "source": [
    "contingency_table = pd.crosstab(data[\"T3_Cat\"], data[\"Cancer\"])\n",
    "chi2_stat, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"T3호르몬 수치 -> 갑상선 암 발병\")\n",
    "print(f\"카이제곱 통계량: {chi2_stat:.4f}\")\n",
    "print(f\"p-value: {p: .4f}\")\n",
    "\n",
    "contingency_table = pd.crosstab(data[\"T4_Cat\"], data[\"Cancer\"])\n",
    "chi2_stat, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print()\n",
    "print(f\"T4호르몬 수치 -> 갑상선 암 발병\")\n",
    "print(f\"카이제곱 통계량: {chi2_stat:.4f}\")\n",
    "print(f\"p-value: {p: .4f}\")\n",
    "\n",
    "contingency_table = pd.crosstab(data[\"T3&T4\"], data[\"Cancer\"])\n",
    "chi2_stat, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print()\n",
    "print(f\"T3호르몬&T4호르몬 -> 갑상선 암 발병\")\n",
    "print(f\"카이제곱 통계량: {chi2_stat:.4f}\")\n",
    "print(f\"p-value: {p: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b89976c0-fbf3-4860-ac90-f475b6aa6552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3호르몬 수치 -> 갑상선 암 발병\n",
      "카이제곱 통계량: 1.3974\n",
      "p-value: 0.4972\n",
      "\n",
      "인종 -> 갑상선 암 발병\n",
      "카이제곱 통계량: 1384.2394\n",
      "p-value: 0.0000\n",
      "\n",
      "T3호르몬 수치 & 인종 -> 갑상선 암 발병\n",
      "카이제곱 통계량: 1398.3145\n",
      "p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "contingency_table = pd.crosstab(data['T3_Cat'], data['Cancer'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"T3호르몬 수치 -> 갑상선 암 발병\")\n",
    "print(f\"카이제곱 통계량: {chi2:.4f}\")\n",
    "print(f\"p-value: {p:.4f}\")\n",
    "\n",
    "contingency_table = pd.crosstab(data['Race'], data['Cancer'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print()\n",
    "print(f\"인종 -> 갑상선 암 발병\")\n",
    "print(f\"카이제곱 통계량: {chi2:.4f}\")\n",
    "print(f\"p-value: {p:.4f}\")\n",
    "\n",
    "contingency_table = pd.crosstab(data['Race_T3'], data['Cancer'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print()\n",
    "print(f\"T3호르몬 수치 & 인종 -> 갑상선 암 발병\")\n",
    "print(f\"카이제곱 통계량: {chi2:.4f}\")\n",
    "print(f\"p-value: {p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae2270b9-ef83-4e9f-9ccb-38553a39e583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요오드 결핍 여부 -> 갑상선 암 발병\n",
      "카이제곱 통계량: 556.3569\n",
      "p-value: 0.0000\n",
      "\n",
      "가족력 여부 -> 갑상선 암 발병\n",
      "카이제곱 통계량: 1000.5772\n",
      "p-value: 0.0000\n",
      "\n",
      "요오드 결핍 여부 & 가족력 여부 -> 갑상선 암 발병\n",
      "카이제곱 통계량: 1554.4941\n",
      "p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "contingency_table = pd.crosstab(data['Iodine_Deficiency'], data['Cancer'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"요오드 결핍 여부 -> 갑상선 암 발병\")\n",
    "print(f\"카이제곱 통계량: {chi2:.4f}\")\n",
    "print(f\"p-value: {p:.4f}\")\n",
    "\n",
    "contingency_table = pd.crosstab(data['Family_Background'], data['Cancer'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print()\n",
    "print(f\"가족력 여부 -> 갑상선 암 발병\")\n",
    "print(f\"카이제곱 통계량: {chi2:.4f}\")\n",
    "print(f\"p-value: {p:.4f}\")\n",
    "\n",
    "contingency_table = pd.crosstab(data['Family&Iodine'], data['Cancer'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print()\n",
    "print(f\"요오드 결핍 여부 & 가족력 여부 -> 갑상선 암 발병\")\n",
    "print(f\"카이제곱 통계량: {chi2:.4f}\")\n",
    "print(f\"p-value: {p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b5008-4c71-4f84-8ce8-6a1a71fb5ee5",
   "metadata": {},
   "source": [
    "# 10. 자료 및 코드 출처\n",
    "1. DACON: [Baseline] SMOTE를 활용한 XGBoost 기반의 갑상선암 분류 中\n",
    "2. ChatGPT: 통계 t-검정 관련 참조\n",
    "3. Claude: 하이퍼 파라미터 튜닝 부분 中 GridSearchCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
